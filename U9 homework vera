library(ggplot2)
library(car)
library(pastecs)


###NOTE: for reporting, remember to mention if you have performed a one-tailed t-test


###Warm-up Exercises

#When you are comparing the means from 2 conditions in an experiment, and the same participants participated in both conditions, what kind of test should you run?
#Dependent t-test

#When you are comparing the means from 2 conditions in an experiment, and different participants participated in the 2 conditions, what kind of test should you run?
#Independent	t-test	

#When you are comparing the means from 3 or more conditions in an experiment, what kind of test should you run?
#Are all the means equal? ANOVA (analysis of variance) 
#Means aren’t all equal, then which means are unequal, and by how much? Tukey’s HSD (Honestly Significant Difference).

###Main Exercises

###1a Load in Smartphone.csv. This spreadsheet contains data from a study on consumer satisfaction with Apple versus Samsung smartphones. In this between-subjects design experiment, participants were given either an Apple or a Samsung phone, told to use it for a week, and then assigned it a rating based on their satisfaction. You are curious whether the mean satisfaction for one phone is greater than the other (but you don't have a specific hypothesis about which phone should be better). 
#Perform the approprite analysis. 
#Make sure to plot your data, 
#test assumptions, 
#run the appropriate test, 
#and report the results. If you violate assumptions, perform an alternative test.

read_smartphone <- read.table(file.choose(), header=TRUE, sep="\t", quote="", comment.char="", fill=TRUE)

#The data of Smartphone.csv is in the long format. And because the participants were either given an Apple or a Samsung phone, the data is independent. So a independent t test should be used. We do a two-tailed test


#Assumptions:


#Normal distribution:
shapiro.test(read_smartphone$Rating)
#So: "According to the shapirotest, the rating of the data of the smarthphones, W = 0,9854 and p-value = 0.4981 were not significantly non-normal." So normally distributed.

by( read_smartphone$Rating, read_smartphone$Brand, stat.desc, basic=FALSE, norm=TRUE)
#So interval level: measurement the distance between attributes have meaning

ggplot(read_smartphone, aes(Brand, Rating)) + geom_boxplot(notch=TRUE) + stat_summary(fun.y=mean, geom="point", colour="red")
#So we can conclude out of the plot that the mean satisfaction for one phone is greater than the other. The mean of Samsung is higher than apple.

#Then we preform a t-test.
tSmartphone <- t.test(Rating ~ Brand, data= read_smartphone); tSmartphone
#The p-value is >0.05 (0.1225). 

###Calculating an effect size

#r = sqrt(-1.5669^2 / (-1.5669^2 + 59.429))

sqrt(((-1.5669)^2 / ((-1.5669)^2 + 59.429)))
#0.1991826. We can consider this as a small effect

#On	average,	participants	with Samsung phones had a higher rating 	(mean	=	74.70 ,	SE	=	2.4511117),	than with Apple phones (mean	=	70.35,	SE	=	1.3036192 ).	According	to	a	t-test	for	independent	samples,	this	difference	was	not	significant,	t(59.429 (df))	=	-1.5669,	p	>	.05 (0.1225): small effect,	r	=	0.199.	

#So no assumptions were violated.


###1b The consumer research agency that conducted the study in 1a informs you that they made it mistake in their original communication with you: in fact, the study was conducted with a within-subjects design. Thus, the first rating for the Samsung phone is from the same study participant as the first rating for the Apple phone (and so forth). Rerun your analysis from 1a, but with the necessary changes appropriate to a within-subjects design.

#The data of Smartphone.csv is in the long format. And because the participants had an Apple and a Samsung phone, the data is dependent. So a dependent t test should be used. 

#Assumptions:


#Normal distribution:
shapiro.test(read_smartphone$Rating)
#So: "According to the shapirotest, the rating of the data of the smarthphones, W = 0,9854 and p-value = 0.4981 were not significantly non-normal." So normally distributed.

differencesSmartphone <- subset(read_smartphone, Brand=="Apple")[,"Rating"] - subset(read_smartphone, Brand=="Samsung")[,"Rating"]

shapiro.test(differencesSmartphone)
#So: "According to the shapirotest, the rating of the data of the smarthphones, W = 0.95698 and p-value = 0.1319 were not significantly non-normal." So normally distributed.


by( read_smartphone$Rating, read_smartphone$Brand, stat.desc, basic=FALSE, norm=TRUE)
#So interval level: measurement the distance between attributes have meaning

ggplot(read_smartphone, aes(Brand, Rating)) + geom_boxplot(notch=TRUE) + stat_summary(fun.y=mean, geom="point", colour="red")
#So we can conclude out of the plot that the mean satisfaction for one phone is greater than the other. The mean of Samsung is higher than apple.

#Then we preform a t-test.
tSmartphoneTest <- t.test(Rating ~ Brand, data= read_smartphone, paired=TRUE); tSmartphoneTest
#The p-value is <0.05 (0.003113). 

###Calculating an effect size

#r = sqrt(-3.152^2 / (-3.152^2 + 39))

sqrt(((-3.152)^2 / ((-3.152)^2 + 39)))
#0.4505842. We can consider this as a medium-sized effect (0.3 is regarded as medium-sized)

#On	average,	participants	with Samsung phones had a higher rating 	(mean	=	74.70 ,	SE	=	2.4511117),	than with Apple phones (mean	=	70.35,	SE	=	1.3036192 ).	According	to	a	t-test	for	dependent	samples,	this	difference	was	not	significant,	t(39 (df))	=	-3.152,	p	<	.05 (0.003113): medium effect,	r	=	0.45.	



###1c Why do you think the p-values in 1a and 1b differ? It may be helpful to create a scatterplot that compares, for each study participant, the Samsung rating they gave (x-axis) against the Apple rating they gave (y-axis).

#P-value of 1a: P>0.05 (0.1225)
#P-value of 1b: P<0.05 (0.003113)
#The p-value in 1a with independent data is higher than the p-value in 1b with dependent data.
???

###1d You discover results from a previous study that suggests that Samsung phones are better liked. Thus, you update your hypothesis to a directional one: you now expect the Samsung phone ratings to be on average HIGHER than the Apple ones. Rerun your analysis from 1b to reflect the change to the hypothesis.

#The data of Smartphone.csv is in the long format. And because the participants had an Apple and a Samsung phone, the data is dependent. So a dependent t test should be used. 

#Assumptions:


#Normal distribution:
shapiro.test(read_smartphone$Rating)
#So: "According to the shapirotest, the rating of the data of the smarthphones, W = 0,9854 and p-value = 0.4981 were not significantly non-normal." So normally distributed.

differencesSmartphone <- subset(read_smartphone, Brand=="Apple")[,"Rating"] - subset(read_smartphone, Brand=="Samsung")[,"Rating"]

shapiro.test(differencesSmartphone)
#So: "According to the shapirotest, the rating of the data of the smarthphones, W = 0.95698 and p-value = 0.1319 were not significantly non-normal." So normally distributed.


by( read_smartphone$Rating, read_smartphone$Brand, stat.desc, basic=FALSE, norm=TRUE)
#So interval level: measurement the distance between attributes have meaning

ggplot(read_smartphone, aes(Brand, Rating)) + geom_boxplot(notch=TRUE) + stat_summary(fun.y=mean, geom="point", colour="red")
#So we can conclude out of the plot that the mean satisfaction for one phone is greater than the other. The mean of Samsung is higher than apple.

#Then we preform a t-test.
tSmartphoneTestthird <- t.test(Rating ~ Brand, data= read_smartphone, paired=TRUE, alternative = "greater"); tSmartphoneTestthird 
#The p-value is >0.05 (0.9984). 

###Calculating an effect size

#r = sqrt(-3.152^2 / (-3.152^2 + 39))

sqrt(((-3.152)^2 / ((-3.152)^2 + 39)))
#0.4505842. We can consider this as a medium-sized effect (0.3 is regarded as medium-sized)

#On	average,	participants	with Samsung phones had a higher rating 	(mean	=	74.70 ,	SE	=	2.4511117),	than with Apple phones (mean	=	70.35,	SE	=	1.3036192 ).	According	to	a	t-test	for	dependent	samples,	this	difference	was	significant,	t(39 (df))	=	-3.152,	p	<	.05 (0.003113): medium effect,	r	=	0.45.	

#So hypothesis of: "you now expect the Samsung phone ratings to be on average HIGHER than the Apple ones" is correct.

###1e Why do you think the p-values in 1b and 1d differ (see our discussion way back from chapter 2)?
#There is a big difference between one tailed and two tailed tests. If you picture a graph of normal distribution: one tailed is only one side of the graph, two tailed is both sides of the graph. So if you have a p-value, for the one tailed test you would divide the value by two (or ofcourse 1 - the value). But with a two tailed test, the p-value is just that value. So for the two tailed test, the p value will be bigger.And therefore the p-values in 1b and 1 differ: one tailed and two tailed. 
